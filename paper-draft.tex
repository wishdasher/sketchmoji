\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\title{SketchMoji}
\author{Margaret Sands and Sophie Mori}
\date{}
\begin{document}

\maketitle
\includegraphics[scale=.6]{sketchmoji}

We built a way to recognize emoji characters from sketches drawn by a user. The user draws a desired emoji in the SketchMoji interface, and the top five most similar results are returned for the user to copy and use. SketchMoji uses a HTML/JavaScript frontend for the interface and a python backend, combined using a Flask server API.

TODO: HOW IT WORKED/HOW WELL HERE
The cover of your term paper should be a graphic and an abstract describing the task, what you built, what hardware/software it used, how it worked, and how well. See below for an example.

\section{Introduction}

Digital media pushed our conception of text-based communication beyond mere words. Nowadays, users of digital technology have found another way to express intent and emotion—through the use of emoji, pictoral ideograms that fall inline with traditional text. Emoji use proliferates social media and instant messaging, but it is also infiltrating web page content and even mainstream media. Emoji constitute a large part of popular culture, and the �� emoji was named Word of the Year by Oxford Dictionaries in 2015.

Currently, the ways to input emoji characters into text on a computer are lacking in usability and efficiency. The user can memorize and utilize custom hotkey combinations on a keyboard; Google a description of the emoji, find the character, copy, and past; or scroll through long, unintuitively sorted menus that some interfaces employ. In systems where each emoji has a named shortcut (e.g. :zipper\_mouth\_face: in Slack), it is difficult to recall or discover the exact name, and the user is resigned to one of the aforementioned methods.

We propose a system that allows users to discover their intended emoji by "drawing" it. Because emoji are rooted in images, we believe this is a more natural and intuitive way to input emoji into text.


\section{System Design}

From the user's end, SketchMoji is a very simple interface. To use SketchMoji, the user visits the web application and uses their computer cursor to draw their conceptional notion of the desired emoji in the drawing area. With each stroke drawn, the system compares the sketch to those of all emoji it knows about, and returns the closest five, ordered by similarity. The user can copy the desired emoji at any point to their clipboard, paste it into the intended destination, and resume their workflow.

The backend takes the timestamped positional data of the drawing, finds the segments in the point data, and then compares critical points to templates to arrive at a classification. These steps are further explained in the following section.

\section{How it Works}

The backend system is mostly based on the sketch recognition mini project. The drawing area captures the user's cursor positions and timestamps as they sketch the emoji. This information is fed into a segmenter, which analyzes the points for curvature and pen (cursor) speed to derive the segmentation points and intended segments of the sketch. We calculate the points of interest—the endpoints and midpoints of segments—and compare those to the points from templates we drew for each emoji. The emoji with templates that are the closest given our distance metric are sent back to the interface for the user to choose from.

TODO: talk about distance metrics

TODO: Talk about emoji set.

b) Describe how well it works. Do the best you can to explain why it had this performance. What experiments did you do? What did it do well and what did it do badly? Provide an example of an interesting failure and explain in detail what the failure was, what made it interesting, and what you learned from it.

Sketchmoji's ability to recognize emoji varies heavily with the particular emoji. The simple ones, such as the checkmark ✔️, party popper ��, and heart ��, are almost always the "most similar" returned result. More complicated emoji, such as a face emoji ��, have a much lower accuracy rate due to a dependence on how similarly the user's mental notion of the emoji matched with those of the template drawers'.

Multiple templates

Rotation

System variance
Many of the improvements we tried did not

c) What in the implementation turned out to be more difficult than expected and why? (e.g., the Leap sensor was insufficiently accurate in some way, which you should describe). What did you do about that difficulty?
d) What worked easily?



One interesting failure is in the segmentation process. For emojis where the user wants to put a small dot for an eye, the smoothing causes the small points to be ignored so the eyes do not get included in the template. This made us realize that in the future we should update the point of interest calculation to deal with short separate strokes.

One implementation issue was copying values on click to the clipboard. Javascript only allows copying from a textarea so we had to create a temporary textarea to copy from and the remove from the interface.

The repurposing of the mini-project 1 code was both harder and easier than expected. The code itself was very modular and easy to change what functions called others. On the other hand, it took a long time for us to realize that matplotlib causes flask to break so anytime the code is being run on the server all matplotlib code must be removed.

\section{Modifications}

The fully streamlined vision for SketchMoji, as envisioned in our original proposal, would be a browser extension or a native application that would insert this drawing area and emoji suggestion list as an overlay on top of whatever application the user is already using. The overlay could be triggered by a hotkey, and clicking on the desired emoji would insert it into the text at the cursor location, eliminating the need to navigate to a separate application and going through copy and paste motions. Because our focus resided in seeing if we could reliably recognize emoji through sketch and not engineering a browser extension, we settled on this standalone web application.

One of our original ideas was to have two modes in the application: the recognizer, which would try to recognize the emoji the user is drawing and the recommender, which would suggest emoji similar to what the user is drawing. Having the recommender means that users could potentially discover new emoji they were not aware of to use. However, we realized that the functionality for the recognize mode iss improved by recommending a list of the most similar matches. The system also essentially returns the same information for both modes. Since the overall experience is streamlined significantly by having a single mode that serves both functionalities, we removed the mode setting.

We believe our system can be improved with a robust variety of template drawings, and one roadblock was collecting those from different sources. We did not modify our project, per se, but we did have to make do with a more limited set of templates.

\section{User Study}

We were fortunate enough be able to conduct live user studies on some roommates. From the first user test, we learned that the name "SketchMoji" and the prototype interface were enough to tell the user what to do with the interface. However, it also showed us that users focus on different features drawing an emoji and that our single-template approach was not comprehensive enough to cover all of those possibilities. In our next iteration, we added the multi-template matching approach.

For our second user study, we had each user sketch an emoji in one go until the expected emoji was in the top three suggestions. If the user could not create a sketch that gave the correct emoji as a suggestion, we maked that down as a failure and user moved on to the next emoji. The results of this experiment will be discussed in performance. Outside of finding the accuracy of the system, this user study gave us additional interesting observations.

Users with a digital mouse could draw at incredibly fast speeds. Because these users did not slow down at inflection points, many points of interest were missed causing their suggestions to be less accurate. We then further tuned the threshold parameters to increase the cutoff speed of inflection points, which increased the accuracy of these quick sketches.

\section{Performance}
7) Performance
a) A crucial thing about the project is what you learned from it, whether or not it worked
perfectly. Good performance that you can’t explain isn’t worth much, while
disappointing performance that arises for an interesting reason can be quite important.
\\
We measured our performance through user testing. The mean score across all users for the test described in the user study section was 16.3 which meant that on average users missed 1-2 emojis. We found that one emoji (the thumbs up emoji) could not be produced in many trials which may have been due to a template issue rather than an issue with the system.
b) Give an example that’s just out of reach for your system – what’s an interesting next step
that it can’t quite do. As mentioned in class, this is an excellent way to explain both the
power and the limits of what you’ve created, and set the stage for the next person’s work.

One example that is currently just out of reach is rotations of emojis. In order to account for differences in emojis across systems and users not knowing the canonical directions, we have added additional templates for known possibilities. However, the original template matching paper by Kara and Stahovich mentions a possible implementation of polar rotation which could fix this issue.

c) Describe what you would do next to improve the system, to take its performance to the
next level.

Currently, there are some emojis where we do not have data similar to how some users could possibly draw them. For those, there is a high chance of mislabelling them when a new user tries Sketchmoji. An interesting next step would be to have a teaching mode for Sketchmoji where a user can make a new sketch and tell sketchmoji to use that as a template for that emoji when they are using the interface.


Improvement ideas:

imporvmeents: prior on user's drawing patterns and usage
some emoji are just too hard to draw

*i think it should be appears at anytime bc the user would probably give up once they see it
\section{Tools, Packages, and Libraries}

The system uses a HTML/JavaScript frontend with a backend Python server. The classification code requires some common packages such as numpy and scipy. We use Flask (https://flask.palletsprojects.com/en/1.1.x/) to serve the application and set up endpoints. The resulting application takes in GET and POST requests from a specific url, runs the corresponding functions, and returns the response. One potential issue is that local versions can hit errors with Cross Origin Requests; future iterations would need to install Flask$_$cors and configure their app accordingly.


\section{Contributions}

Our SketchMoji interface, which we used to generate and select all emoji characters used in this paper.


imporvmeents: prior on user's drawing patterns and usage
some emoji are just too hard to draw


\end{document}

